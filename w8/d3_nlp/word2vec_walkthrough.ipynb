{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94beb8e5-8ce4-4e60-b9c0-b2f3ebfec5b9",
   "metadata": {},
   "source": [
    "Once we have the model loaded in Python, we can play with its different pre-built functions. Firstly, we can find the numeric vector for every word (it will always have length of 300).\n",
    "\n",
    "https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8b12089-6fc7-4728-a224-6720c27d382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "\n",
    "word2vec_path = 'data/GoogleNews-vectors-negative300.bin.gz'\n",
    "model = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c0615a-30af-4593-874b-fdd25224f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c480d8-d5ff-481c-b2a3-5a0d80a2c936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model['easy']\n",
    "\n",
    "# see the shape of the vector - will always have length (300,)\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde98364-1314-423d-9469-e89e4765b41a",
   "metadata": {},
   "source": [
    "### Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc032ab-7b81-45d2-baba-f1feae412153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 0.6836091876029968),\n",
       " ('lovely', 0.6676310896873474),\n",
       " ('neat', 0.6616737246513367),\n",
       " ('fantastic', 0.6569240689277649),\n",
       " ('wonderful', 0.6561347246170044),\n",
       " ('terrific', 0.6552367806434631),\n",
       " ('great', 0.6454657912254333),\n",
       " ('awesome', 0.6404187679290771),\n",
       " ('nicer', 0.6302445530891418),\n",
       " ('decent', 0.5993332862854004)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can find the most similar words to any word\n",
    "model.most_similar(\"nice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4682eea2-5e14-48b6-81de-94a95a98ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6836092"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or a similarity score of any two words:\n",
    "model.similarity(\"nice\",\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ff4d7-9a97-40dc-b89f-3de38fc914df",
   "metadata": {},
   "source": [
    "Interestingly, if we take two antonyms (words with opposite meaning), they are going to be highly similar according to a good Word2Vec model. This because we can usually replace opposite words with each other in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ad0ff5a-a637-4603-957a-2ca70872f701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7190051"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interesting\n",
    "model.similarity(\"bad\",\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2457af3c-cdc2-4949-ad7f-4c8505fe9751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also look for interesting relationships between words.\n",
    "\n",
    "# king - queen = man - woman\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cf3d4-bc6e-473a-acdb-43a1078e62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mom --> girl, dad --> ?\n",
    "france --> paris, spain --> ?\n",
    "mother --> ?, table --> chair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68a29166-b21f-4bc2-aa0b-be4f5ae6d29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 0.808031439781189),\n",
       " ('teenager', 0.6755869388580322),\n",
       " ('teenage_girl', 0.6386617422103882),\n",
       " ('man', 0.6255338191986084),\n",
       " ('lad', 0.616614043712616),\n",
       " ('schoolgirl', 0.611348032951355),\n",
       " ('schoolboy', 0.6011567115783691),\n",
       " ('son', 0.593845784664154),\n",
       " ('father', 0.5887871384620667),\n",
       " ('uncle', 0.5734449028968811)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['dad', 'girl'], negative=['mom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "525639c2-8b2e-4acf-846b-ec8afa50b4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('madrid', 0.5295541882514954),\n",
       " ('dubai', 0.5092597603797913),\n",
       " ('heidi', 0.48901548981666565),\n",
       " ('portugal', 0.48763689398765564),\n",
       " ('paula', 0.4855714738368988),\n",
       " ('alex', 0.4807346761226654),\n",
       " ('lohan', 0.4801103174686432),\n",
       " ('diego', 0.48010098934173584),\n",
       " ('florence', 0.47695302963256836),\n",
       " ('costa', 0.4761490523815155)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['paris', 'spain'], negative=['france'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "574d0caa-f4ec-478a-b1cd-c10947e8d02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('daughter', 0.6066097021102905),\n",
       " ('niece', 0.5490824580192566),\n",
       " ('granddaughter', 0.5400506854057312),\n",
       " ('aunt', 0.5397382378578186),\n",
       " ('husband', 0.5387389659881592),\n",
       " ('sister', 0.5360148549079895),\n",
       " ('son', 0.5356959104537964),\n",
       " ('wife', 0.5313628911972046),\n",
       " ('father', 0.5261732935905457),\n",
       " ('grandmother', 0.5253341197967529)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mother --> ?, table --> chair\n",
    "model.most_similar(positive=['chair', 'mother'], negative=['table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c5960-1459-4654-bf5a-4d6f8cc725af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
