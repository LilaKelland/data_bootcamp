{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7bb45b",
   "metadata": {},
   "source": [
    "## Training a Keras model to generate colours\n",
    "\n",
    "apply RNn to process character sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f28f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://heartbeat.comet.ml/how-to-train-a-keras-model-to-generate-colors-3bc79e54971b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53965f26",
   "metadata": {},
   "source": [
    "There are two general options for language modeling: word-level models and character-level models. Each has its advantages and disadvantages. Let’s go through them now\n",
    "\n",
    "### Word-level Language Model\n",
    "The word-level language model can handle relatively long and clean sentences. By “clean”, I mean the words in the text datasets are free from typos and have few words outside of English vocabulary. The word-level language model encodes each unique word into a corresponding integer, and there’s a predefined fixed-sized vocabulary dictionary to look up the word to integer mapping. One major benefit of the word-level language model is its ability to leverage pre-trained word embeddings such as Word2Vec or GloVe. These embeddings represent words as vectors with useful properties. Words close in context are close in Euclidean distance and can be used to understand analogies like \"man is to women, as king is to queen\". Using these ideas, you can train a word-level model with relatively small labeled training sets\n",
    "\n",
    "### Character Level Language Model\n",
    "But there’s an even simpler language model, one that splits a text string into characters and associates a unique integer to every single character. There are some reasons you might choose to use the character-level language model over the more popular word-level model:\n",
    "\n",
    "* Your text datasets contain a noticeable amount of out-of-vocabulary words or infrequent words. In our case, some legitimate color names could be “aquatone”, “chartreuse” and “fuchsia”. For me, I have to check a dictionary to find out their meanings, and traditional word-level embeddings may not contain them.\n",
    "* The majority of the text strings are short, bounded-length strings. If you’re looking for a specific length limit, I’ve been dealing with a Yelp review generation model with character level encode character length of 60 and still get decent results. You can find that blog post here: How to generate realistic yelp restaurant reviews with Keras. Usually, the character-level language generation model can create text with more variety since its imagination is not constrained by a pre-defined dictionary of vocabulary.\n",
    "You may also be aware of the limitation that came with adopting character-level language: - Long sequences may not capture long-range dependencies as well as word-level language models. - Character-level models are also more computationally expensive to train — given the same text data sets, these model sequences are longer and, as a result, require extended training time.\n",
    "\n",
    "Fortunately, these limitations won’t pose a threat to our color generation task. We’re limiting our color names to 25 characters in length and we only have 18,606 training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794fed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import preprocessing\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM, Reshape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab005eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>blue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18th Century Green</td>\n",
       "      <td>165</td>\n",
       "      <td>147</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975 Earth Red</td>\n",
       "      <td>123</td>\n",
       "      <td>70</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989 Miami Hotline</td>\n",
       "      <td>221</td>\n",
       "      <td>51</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000 Leagues Under the Sea</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3AM in Shibuya</td>\n",
       "      <td>34</td>\n",
       "      <td>85</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  red  green  blue\n",
       "0           18th Century Green  165    147    68\n",
       "1               1975 Earth Red  123     70    59\n",
       "2           1989 Miami Hotline  221     51   102\n",
       "3  20000 Leagues Under the Sea   25     25   112\n",
       "4               3AM in Shibuya   34     85   119"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can load the data into a Pandas data-frame and create separate series with color names.\n",
    "\n",
    "data = pd.read_csv(\"data/colors.csv\")\n",
    "names = data[\"name\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a871e722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18606, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852c5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9cbb4bc",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "We mentioned that we’re limiting our color names to 25 characters. To arrive at this number, we checked the distribution of the length of color names across all training samples and visualize it to make sure the length limit we pick makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8412abe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = sorted(names.str.len().values)\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as plt\n",
    "\n",
    "fit = stats.norm.pdf(h, np.mean(h), np.std(h))  #this is a fitting indeed\n",
    "plt.plot(h,fit,'-o')\n",
    "plt.hist(h, density=True, stacked=True)      #use this to draw histogram of your data\n",
    "plt.xlabel('Chars')\n",
    "plt.ylabel('Probability density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8a293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18606, 25)\n"
     ]
    }
   ],
   "source": [
    "# See majority have strings <25, max length 30.  Could choose 30, but would need to be trained for longer.  \n",
    "# Transform string to list 25 integer values with text tokenization utility\n",
    "\n",
    "maxlen = 25\n",
    "t = Tokenizer(char_level=True)\n",
    "t.fit_on_texts(names)\n",
    "tokenized = t.texts_to_sequences(names)\n",
    "padded_names = preprocessing.sequence.pad_sequences(tokenized, maxlen=maxlen)\n",
    "print(padded_names.shape)\n",
    "\n",
    "# If a string has less than 25 characters, it will be padded with the value 0 from the beginning of the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e4344c",
   "metadata": {},
   "source": [
    "### One-hot Encoding\n",
    "We can view the character to integer mapping by inspecting the t.word_index property of the instance of Keras’ Tokenizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "864cfe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': 1, 'a': 2, ' ': 3, 'r': 4, 'i': 5, 'l': 6, 'n': 7, 'o': 8, 's': 9, 't': 10, 'c': 11, 'u': 12, 'd': 13, 'g': 14, 'p': 15, 'h': 16, 'b': 17, 'm': 18, 'y': 19, 'w': 20, 'k': 21, 'f': 22, 'v': 23, 'z': 24, 'j': 25, 'q': 26, 'x': 27, \"'\": 28, '-': 29, 'ō': 30, 'è': 31, 'é': 32, 'ā': 33, 'á': 34, 'ó': 35, 'ū': 36, '0': 37, '8': 38, '.': 39, 'ē': 40, 'ī': 41, 'ǎ': 42, '!': 43, 'í': 44, '&': 45, 'ǜ': 46, '9': 47, '2': 48, 'à': 49, 'ǐ': 50, '’': 51, '6': 52, 'ú': 53, '1': 54, '3': 55, 'â': 56, '4': 57, 'ǔ': 58, 'ì': 59, '7': 60, '5': 61, 'ê': 62, 'ö': 63, 'ł': 64, 'š': 65, 'ü': 66, '₂': 67, 'ò': 68, 'ñ': 69, 'ě': 70, 'ń': 71, 'ä': 72, 'œ': 73, 'ß': 74, '%': 75, 'ı': 76, 'ż': 77, '/': 78, 'î': 79, 'ë': 80, '(': 81, ')': 82, 'å': 83, '$': 84, 'я': 85, 'ő': 86, 'ğ': 87, 'ç': 88, 'ù': 89}\n"
     ]
    }
   ],
   "source": [
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc81059",
   "metadata": {},
   "source": [
    "We can see that all of the most frequent characters (letters) are in the top 25. Therefore, this number should be sufficient.\n",
    "\n",
    "However, the integer values have no natural ordered relationship between each other and our model may not be able to harness any benefit from it. What’s worse, our model will initially assume such an ordering relationship among those characters (i.e. “a” is 2 and “e” is 1 but that should not signify a relationship), which can lead to an unwanted result. We will use one-hot encoding to represent the input sequence.\n",
    "\n",
    "Each integer will be represented by a boolean array where only one element in the array will have a value of 1. The max integer value will determine the length of the boolean array in the character dictionary.\n",
    "\n",
    "In our case, the max integer value is 'ù': 89, so the length of a one-hot boolean array will be 90 (considering the lowest value starts with 0, which is the padding).\n",
    "\n",
    "For example, instead of using the integer value 2 to represent character ‘a’, we’re going to use one-hot array [0, 0, 1, 0 …….. 0].\n",
    "\n",
    "One-hot encoding is also accessible in Keras.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "999b31e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18606, 25, 90)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.utils import np_utils\n",
    "one_hot_names = np_utils.to_categorical(padded_names)\n",
    "one_hot_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d58586",
   "metadata": {},
   "source": [
    "The resulting one-hot-names has the shape (18606, 25, 90), which stands for (# of training samples, max sequence length, # of unique tokens).\n",
    "### Data Normalization\n",
    "Remember we’re predicting 3 color channel values, each value ranging between 0–255. There is no golden rule for data normalization. Data normalization is purely practical because in practice it could take a model forever to converge if the training data values are spread out too much. A common normalization technique is to scale values to [-1, 1]. In our model, we’re using a ReLu activation function in the last layer. Since ReLu outputs non-negative numbers, we’ll normalize the values to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d6dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RGB values are between 0 - 255\n",
    "# scale them to be between 0 - 1\n",
    "def norm(value):\n",
    "    return value / 255.0\n",
    "\n",
    "normalized_values = np.column_stack([norm(data[\"red\"]), norm(data[\"green\"]), norm(data[\"blue\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b993cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64705882, 0.57647059, 0.26666667],\n",
       "       [0.48235294, 0.2745098 , 0.23137255],\n",
       "       [0.86666667, 0.2       , 0.4       ],\n",
       "       ...,\n",
       "       [0.80392157, 0.83529412, 0.83529412],\n",
       "       [0.        , 0.5372549 , 0.58823529],\n",
       "       [0.14117647, 0.54509804, 0.8       ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5cd4e8",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "To build our model we’re going to use two types of neural networks: a feed-forward neural network and a recurrent neural network. The feed-forward neural network is by far the most common type of neural network. In this neural network, the information comes into the input units and flows in one direction through hidden layers until each reaches the output units.\n",
    "\n",
    "In recurrent neural networks, information can flow around in cycles. These networks can remember information for a long time. Recurrent networks are a very natural way to model sequential data. In our specific model, we’re using one of the most powerful recurrent networks named long short term memory (LSTM).\n",
    "\n",
    "The easiest way to build a deep learning model in Keras is to use its sequential API, and we simply connect each of the neural network layers by calling its model.add() function like connecting LEGO bricks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd7477e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 23:44:11.861225: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(maxlen, 90)))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541e67d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 23:44:41.671820: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "466/466 [==============================] - 61s 124ms/step - loss: 0.0685 - acc: 0.5818 - val_loss: 0.0631 - val_acc: 0.6279\n",
      "Epoch 2/40\n",
      "466/466 [==============================] - 61s 131ms/step - loss: 0.0643 - acc: 0.6198 - val_loss: 0.0607 - val_acc: 0.6139\n",
      "Epoch 3/40\n",
      "466/466 [==============================] - 67s 144ms/step - loss: 0.0615 - acc: 0.6325 - val_loss: 0.0600 - val_acc: 0.6274\n",
      "Epoch 4/40\n",
      "466/466 [==============================] - 68s 146ms/step - loss: 0.0592 - acc: 0.6322 - val_loss: 0.0583 - val_acc: 0.6018\n",
      "Epoch 5/40\n",
      "466/466 [==============================] - 67s 143ms/step - loss: 0.0568 - acc: 0.6369 - val_loss: 0.0579 - val_acc: 0.6061\n",
      "Epoch 6/40\n",
      "466/466 [==============================] - 75s 161ms/step - loss: 0.0546 - acc: 0.6406 - val_loss: 0.0563 - val_acc: 0.6136\n",
      "Epoch 7/40\n",
      "466/466 [==============================] - 75s 160ms/step - loss: 0.0525 - acc: 0.6402 - val_loss: 0.0554 - val_acc: 0.6051\n",
      "Epoch 8/40\n",
      "466/466 [==============================] - 69s 148ms/step - loss: 0.0504 - acc: 0.6472 - val_loss: 0.0571 - val_acc: 0.5693\n",
      "Epoch 9/40\n",
      "466/466 [==============================] - 61s 131ms/step - loss: 0.0486 - acc: 0.6495 - val_loss: 0.0548 - val_acc: 0.6051\n",
      "Epoch 10/40\n",
      "466/466 [==============================] - 67s 144ms/step - loss: 0.0461 - acc: 0.6566 - val_loss: 0.0553 - val_acc: 0.6279\n",
      "Epoch 11/40\n",
      "466/466 [==============================] - 71s 153ms/step - loss: 0.0439 - acc: 0.6623 - val_loss: 0.0565 - val_acc: 0.6107\n",
      "Epoch 12/40\n",
      "466/466 [==============================] - 68s 147ms/step - loss: 0.0412 - acc: 0.6684 - val_loss: 0.0573 - val_acc: 0.5903\n",
      "Epoch 13/40\n",
      "466/466 [==============================] - 74s 159ms/step - loss: 0.0382 - acc: 0.6747 - val_loss: 0.0576 - val_acc: 0.5978\n",
      "Epoch 14/40\n",
      "466/466 [==============================] - 67s 144ms/step - loss: 0.0351 - acc: 0.6797 - val_loss: 0.0591 - val_acc: 0.6126\n",
      "Epoch 15/40\n",
      "466/466 [==============================] - 61s 131ms/step - loss: 0.0317 - acc: 0.6899 - val_loss: 0.0622 - val_acc: 0.5879\n",
      "Epoch 16/40\n",
      "466/466 [==============================] - 63s 136ms/step - loss: 0.0283 - acc: 0.6943 - val_loss: 0.0609 - val_acc: 0.5825\n",
      "Epoch 17/40\n",
      "466/466 [==============================] - 64s 137ms/step - loss: 0.0247 - acc: 0.7031 - val_loss: 0.0641 - val_acc: 0.6040\n",
      "Epoch 18/40\n",
      "466/466 [==============================] - 70s 149ms/step - loss: 0.0218 - acc: 0.7087 - val_loss: 0.0642 - val_acc: 0.5935\n",
      "Epoch 19/40\n",
      "466/466 [==============================] - 62s 133ms/step - loss: 0.0184 - acc: 0.7174 - val_loss: 0.0651 - val_acc: 0.5970\n",
      "Epoch 20/40\n",
      "466/466 [==============================] - 68s 145ms/step - loss: 0.0159 - acc: 0.7265 - val_loss: 0.0675 - val_acc: 0.5997\n",
      "Epoch 21/40\n",
      "466/466 [==============================] - 63s 134ms/step - loss: 0.0141 - acc: 0.7366 - val_loss: 0.0676 - val_acc: 0.6026\n",
      "Epoch 22/40\n",
      "466/466 [==============================] - 62s 133ms/step - loss: 0.0122 - acc: 0.7438 - val_loss: 0.0675 - val_acc: 0.5860\n",
      "Epoch 23/40\n",
      "466/466 [==============================] - 63s 135ms/step - loss: 0.0109 - acc: 0.7542 - val_loss: 0.0683 - val_acc: 0.5868\n",
      "Epoch 24/40\n",
      "466/466 [==============================] - 61s 131ms/step - loss: 0.0096 - acc: 0.7581 - val_loss: 0.0692 - val_acc: 0.5973\n",
      "Epoch 25/40\n",
      "466/466 [==============================] - 62s 132ms/step - loss: 0.0086 - acc: 0.7672 - val_loss: 0.0683 - val_acc: 0.5822\n",
      "Epoch 26/40\n",
      "466/466 [==============================] - 61s 130ms/step - loss: 0.0077 - acc: 0.7703 - val_loss: 0.0689 - val_acc: 0.5892\n",
      "Epoch 27/40\n",
      "466/466 [==============================] - 62s 133ms/step - loss: 0.0070 - acc: 0.7812 - val_loss: 0.0679 - val_acc: 0.5870\n",
      "Epoch 28/40\n",
      "466/466 [==============================] - 60s 128ms/step - loss: 0.0064 - acc: 0.7829 - val_loss: 0.0682 - val_acc: 0.5833\n",
      "Epoch 29/40\n",
      "466/466 [==============================] - 60s 130ms/step - loss: 0.0060 - acc: 0.7898 - val_loss: 0.0686 - val_acc: 0.5785\n",
      "Epoch 30/40\n",
      "466/466 [==============================] - 62s 134ms/step - loss: 0.0055 - acc: 0.7958 - val_loss: 0.0692 - val_acc: 0.5725\n",
      "Epoch 31/40\n",
      "466/466 [==============================] - 59s 127ms/step - loss: 0.0053 - acc: 0.7984 - val_loss: 0.0695 - val_acc: 0.5709\n",
      "Epoch 32/40\n",
      "466/466 [==============================] - 62s 132ms/step - loss: 0.0048 - acc: 0.8077 - val_loss: 0.0682 - val_acc: 0.5699\n",
      "Epoch 33/40\n",
      "466/466 [==============================] - 62s 133ms/step - loss: 0.0045 - acc: 0.8113 - val_loss: 0.0700 - val_acc: 0.5828\n",
      "Epoch 34/40\n",
      "466/466 [==============================] - 67s 144ms/step - loss: 0.0045 - acc: 0.8135 - val_loss: 0.0690 - val_acc: 0.5744\n",
      "Epoch 35/40\n",
      "466/466 [==============================] - 68s 146ms/step - loss: 0.0041 - acc: 0.8179 - val_loss: 0.0699 - val_acc: 0.5664\n",
      "Epoch 36/40\n",
      "466/466 [==============================] - 68s 146ms/step - loss: 0.0040 - acc: 0.8238 - val_loss: 0.0684 - val_acc: 0.5755\n",
      "Epoch 37/40\n",
      "466/466 [==============================] - 66s 141ms/step - loss: 0.0037 - acc: 0.8257 - val_loss: 0.0693 - val_acc: 0.5752\n",
      "Epoch 38/40\n",
      "466/466 [==============================] - 68s 146ms/step - loss: 0.0037 - acc: 0.8353 - val_loss: 0.0681 - val_acc: 0.5639\n",
      "Epoch 39/40\n",
      "466/466 [==============================] - 69s 148ms/step - loss: 0.0035 - acc: 0.8323 - val_loss: 0.0668 - val_acc: 0.5849\n",
      "Epoch 40/40\n",
      "466/466 [==============================] - 70s 150ms/step - loss: 0.0034 - acc: 0.8374 - val_loss: 0.0679 - val_acc: 0.5836\n"
     ]
    }
   ],
   "source": [
    "# training a model by calling model.fit() function cannot be any easier\n",
    "history = model.fit(one_hot_names, normalized_values,\n",
    "                    epochs=40,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdac6e8",
   "metadata": {},
   "source": [
    "### Generate Colors\n",
    "Let’s define some functions to generate and show the color predicted.\n",
    "\n",
    "For a color name input, we need to transform it into the same one-hot representation. To achieve this, we tokenize characters to integers with the same tokenizer with which we processed the training data, pad it to the max sequence length of 25, then apply the one-hot encoding to the integer sequence.\n",
    "\n",
    "And for the output RGB values, we need to scale it back to 0–255, so we can display them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aee2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a color image\n",
    "def plot_rgb(rgb):\n",
    "    data = [[rgb]]\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(data, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "def scale(n):\n",
    "    return int(n * 255) \n",
    "\n",
    "def predict(name):\n",
    "    name = name.lower()\n",
    "    tokenized = t.texts_to_sequences([name])\n",
    "    padded = preprocessing.sequence.pad_sequences(tokenized, maxlen=maxlen)\n",
    "    one_hot = np_utils.to_categorical(padded, num_classes=90)\n",
    "    pred = model.predict(np.array(one_hot))[0]\n",
    "    r, g, b = scale(pred[0]), scale(pred[1]), scale(pred[2])\n",
    "    print(name + ',', 'R,G,B:', r,g,b)\n",
    "    plot_rgb(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2c88e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest, R,G,B: 29 81 25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocean, R,G,B: 23 82 145\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let’s give the predict() function a try.\n",
    "\n",
    "predict(\"forest\")\n",
    "predict(\"ocean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b289c",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "In this post, we talked about how to build a Keras model that can take any color name and come up with an RGB color value. More specifically, we looked at how to apply the one-hot encoding to character-level language models, building a neural network model with a feed-forward neural network and recurrent neural network.\n",
    "\n",
    "Here’s a diagram to summarize what we have built in the post, starting from the bottom and showing every step of the data flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455adc87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
