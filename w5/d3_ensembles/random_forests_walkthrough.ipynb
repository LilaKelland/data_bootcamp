{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44573397-f46f-41ea-80e7-47da2fa74f51",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "\n",
    "In the case of regression, the average of all the tree outputs is considered as the final result. \n",
    "\n",
    "It works in four steps:\n",
    "\n",
    "1. Select random samples from a given dataset.\n",
    "2. Construct a decision tree for each sample and get a prediction result from each decision tree.\n",
    "3. Perform a vote for each predicted result.\n",
    "4. Select the prediction result with the most votes as the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f63276-56a4-4a6e-8ab8-a7eb3a5c10ad",
   "metadata": {},
   "source": [
    "#### Advantages:\n",
    "* Random forests is considered as a highly accurate and robust method because of the number of decision trees participating in the process.\n",
    "* It does not suffer from the overfitting problem. The main reason is that it takes the average of all the predictions, which cancels out the biases.\n",
    "* The algorithm can be used in both classification and regression problems.\n",
    "* Random forests can also handle missing values. There are two ways to handle these: using median values to replace continuous variables, and computing the proximity-weighted average of missing values.\n",
    "* You can get the relative feature importance, which helps in selecting the most contributing features for the classifier.\n",
    "#### Disadvantages:\n",
    "* Random forests is slow in generating predictions because it has multiple decision trees. Whenever it makes a prediction, all the trees in the forest have to make a prediction for the same given input and then perform voting on it. This whole process is time-consuming.\n",
    "* The model is difficult to interpret compared to a decision tree, where you can easily make a decision by following the path in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1bbf0-0724-4c23-bac9-1eb9318cc31f",
   "metadata": {},
   "source": [
    "### Finding important features\n",
    "Random forests also offers a good feature selection indicator. Scikit-learn provides an extra variable with the model, which shows the relative importance or contribution of each feature in the prediction. It automatically computes the relevance score of each feature in the training phase. Then it scales the relevance down so that the sum of all scores is 1.\n",
    "\n",
    "This score will help you choose the most important features and drop the least important ones for model building\n",
    "\n",
    "Random forest uses gini importance or mean decrease in impurity (MDI) to calculate the importance of each feature. Gini importance is also known as the total decrease in node impurity. This is how much the model fit or accuracy decreases when you drop a variable. The larger the decrease, the more significant the variable is. Here, the mean decrease is a significant parameter for variable selection. The Gini index can describe the overall explanatory power of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae002b63-5444-461f-acf8-d53b2b291340",
   "metadata": {},
   "source": [
    "### Random Forests vs Decision Trees\n",
    "* Random forests is a set of multiple decision trees.\n",
    "* Deep decision trees may suffer from overfitting, but random forests prevents overfitting by creating trees on random subsets.\n",
    "* Decision trees are computationally faster.\n",
    "* Random forests is difficult to interpret, while a decision tree is easily interpretable and can be converted to rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0abfbc-7a1e-4833-a0a5-efa650d8c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5a9183-32cf-4a6c-805f-b839254e88f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print the label species(setosa, versicolor,virginica)\n",
    "print(iris.target_names)\n",
    "\n",
    "# print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ff9257-95f6-4c65-ab07-b574cc6a55fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# It's a good idea to always explore your data a bit,\n",
    "# print the iris data (top 5 records)\n",
    "print(iris.data[0:5])\n",
    "\n",
    "# print the iris labels (0:setosa, 1:versicolor, 2:virginica)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503b6528-c3ea-4a63-9eb9-6a8ded08de5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame of given iris dataset.\n",
    "import pandas as pd\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9223f63-122e-4452-96eb-49eb7f4163b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=data['species']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba299fc-e1f0-456d-8809-3d1f959edd5b",
   "metadata": {},
   "source": [
    "train the model on the training set and perform predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e59e7e84-8891-43f5-a9ce-638315008d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946350e-ec9d-4892-8d1a-9a206be229cc",
   "metadata": {},
   "source": [
    "After training, check the accuracy using actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "941e7c92-3f68-4b0e-b0e4-32ab5850ff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce149505-46dd-4f29-9a9d-2abbc01f15fb",
   "metadata": {},
   "source": [
    "You can also make a prediction for a single item, for example:\n",
    "\n",
    "sepal length = 3\n",
    "sepal width = 5\n",
    "petal length = 4\n",
    "petal width = 2\n",
    "Now you can predict which type of flower it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb57485-853d-4635-b58e-5730d969fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilakelland/opt/anaconda3/envs/bootcamp_env/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[3, 5, 4, 2]])\n",
    "\n",
    "# Here, 2 indicates the flower type Virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe539c-83bf-421c-99f6-bce5e3e7e8d6",
   "metadata": {},
   "source": [
    "### Finding Important Features \n",
    "* First, you need to create a random forests model.\n",
    "* Second, use the feature importance variable to see feature importance scores.\n",
    "* Third, visualize these scores using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a40779-b210-4190-95ad-05fdc1ceaa3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "536ec5f2-05a6-45cf-afb8-40e30b438da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, #min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e819d613-bbdf-41a5-ac0b-850ed01f33c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal length (cm)    0.448861\n",
       "petal width (cm)     0.421592\n",
       "sepal length (cm)    0.106461\n",
       "sepal width (cm)     0.023086\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d80506c0-3a27-457b-832f-70f291ab6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d448dcb-ba56-4917-b2d6-31a67233a711",
   "metadata": {},
   "source": [
    "### Generating the Model on Selected Features\n",
    "Here, you can remove the \"sepal width\" feature because it has very low importance, and select the 3 remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78561d46-234f-4455-99cb-3fd486a6be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into features and labels\n",
    "X=data[['petal length', 'petal width','sepal length']]  # Removed feature \"sepal length\"\n",
    "y=data['species']                                       \n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=5) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110c11d-e2dc-4558-b85e-0afa1f4eade2",
   "metadata": {},
   "source": [
    "After spliting, you will generate a model on the selected training set features, perform predictions on the selected test set features, and compare actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "986e0426-92cb-41f2-9b16-f7a39f5c9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5f531-b3dd-4d80-aaad-7a79070a93c3",
   "metadata": {},
   "source": [
    "You can see that after removing the least important features (sepal length), the accuracy increased. This is because you removed misleading data and noise, resulting in an increased accuracy. A lesser amount of features also reduces the training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641d67b-ab71-4239-9997-770428c66cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_env",
   "language": "python",
   "name": "bootcamp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
