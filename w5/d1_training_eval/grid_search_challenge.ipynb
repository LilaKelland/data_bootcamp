{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of sales\n",
    "\n",
    "### Problem Statement\n",
    "This dataset represents sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store are available. The aim is to build a predictive model and find out the sales of each product at a particular store.\n",
    "\n",
    "|Variable|Description|\n",
    "|: ------------- |:-------------|\n",
    "|Item_Identifier|Unique product ID|\n",
    "|Item_Weight|Weight of product|\n",
    "|Item_Fat_Content|Whether the product is low fat or not|\n",
    "|Item_Visibility|The % of total display area of all products in a store allocated to the particular product|\n",
    "|Item_Type|The category to which the product belongs|\n",
    "|Item_MRP|Maximum Retail Price (list price) of the product|\n",
    "|Outlet_Identifier|Unique store ID|\n",
    "|Outlet_Establishment_Year|The year in which store was established|\n",
    "|Outlet_Size|The size of the store in terms of ground area covered|\n",
    "|Outlet_Location_Type|The type of city in which the store is located|\n",
    "|Outlet_Type|Whether the outlet is just a grocery store or some sort of supermarket|\n",
    "|Item_Outlet_Sales|Sales of the product in the particulat store. This is the outcome variable to be predicted.|\n",
    "\n",
    "Please note that the data may have missing values as some stores might not report all the data due to technical glitches. Hence, it will be required to treat them accordingly.\n",
    "\n",
    "\n",
    "\n",
    "### Explore the problem in following stages:\n",
    "\n",
    "1. Hypothesis Generation – understanding the problem better by brainstorming possible factors that can impact the outcome\n",
    "2. Data Exploration – looking at categorical and continuous feature summaries and making inferences about the data.\n",
    "3. Data Cleaning – imputing missing values in the data and checking for outliers\n",
    "4. Feature Engineering – modifying existing variables and creating new ones for analysis\n",
    "5. Model Building – making predictive models on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have covered data preparation and feature engineering two weeks ago. Now, it's time to do some predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "## Task\n",
    "Make a baseline model. Baseline models help us set a benchmark to gauge the performance of our future models. If your new model is below the baseline, something has gone wrong, and you should check your data.\n",
    "\n",
    "To make a baseline model, run a simple regression model without altering the default parameters in sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fixed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 39)\n"
     ]
    }
   ],
   "source": [
    "# CHANGE OUT DUMMY WITH ONE HOT ENCODING NO _ IF >6 LABEL ENCODING? - OR USE CORRELATION FUNCTION TO REMOVE\n",
    "# TRY BINNING FOR IE YEARS _OPENED AND OTHER TO MAKE CATEGROICAL _ DO FOR THINGS LIKE AGE\n",
    "# CHECK IF EACH VARIABLE IS LINEAR _ PERHAPS NEED TO TAKE LOG IF SKEWED OR POLYNOMIAL FIT IF NON LINEAR\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "y = df.Item_Outlet_Sales\n",
    "X = df.drop(columns=['Item_Outlet_Sales', 'Outlet_Establishment_Year', 'Unnamed: 0'])\n",
    "# X.columns\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8,test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print out the numeric columns and categorical columns as numeric_cols and cat_cols \n",
    "\n",
    "# numeric_cols = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Years_Opened']\n",
    "# cat_cols = list(set(X.columns) - set(numeric_cols))\n",
    "# cat_cols.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FROM EXERCISE\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "# def get_features_and_target_arrays(df, numeric_cols, cat_cols, scaler):\n",
    "#     X_numeric_scaled = scaler.transform(df[numeric_cols])\n",
    "#     X_categorical = df[cat_cols].to_numpy()\n",
    "#     X = np.hstack((X_categorical, X_numeric_scaled))\n",
    "# #     y = df['target']\n",
    "#     return X #, y\n",
    "\n",
    "# X_train= get_features_and_target_arrays(X_train, numeric_cols, cat_cols, scaler)\n",
    "# # X\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO I NEED TO BE SCALING FIRST - CAUSE I SURE DID  \n",
    "## ALSO I DIDN\"T SCALE Y - PROB NEED TO DO THAT?\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# creating linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_lr_baseline = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_lr 1204691.7533316647\n",
      "r2_baseline 0.557970448584349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "MSE_lr_baseline = mean_squared_error(y_test,y_lr_baseline) \n",
    "r2_baseline = r2_score(y_test,y_lr_baseline)\n",
    "print(\"MSE_lr\", MSE_lr_baseline)\n",
    "print(\"r2_baseline\", r2_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Split your data in 80% train set and 20% test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Use grid_search to find the best value of the parameter `alpha` for Ridge and Lasso regressions from `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW DO WE GET CROSS VALIDATION SCORE FOR EACH? OR I GUESS WE DONT NEED HAVE THE BEST? DOES IT AVERAGE FOR US?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R_squared from grid search: 0.564\n",
      "{'alpha': 10.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Ridge()\n",
    "param_grid = {\n",
    "    #     'alpha': np.arange(0, 1, 0.1)\n",
    "    'alpha': np.arange(10, 20, 0.1)\n",
    "#     'alpha' : [1,0.1,0.01,0.001,0.0001,0]\n",
    "}\n",
    "\n",
    "grid_search_ridge = GridSearchCV(model, param_grid, cv=10)\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "#  Results\n",
    "print(\"Best R_squared from grid search: %.3f\"\n",
    "       % grid_search_ridge.score(X_train, y_train))\n",
    "print(grid_search_ridge.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use alpha found to fit ridge\n",
    "rr = Ridge(alpha=10)\n",
    "rr.fit(X_train,y_train)\n",
    "y_rr = rr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R_squared from grid search: 0.561\n",
      "{'alpha': 11.0}\n"
     ]
    }
   ],
   "source": [
    "# WHY IS CAN\"T IFIND THIS IN THE SAME PLACE AS RIDGE?\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso()\n",
    "np.arange(1, 50, 3)\n",
    "param_grid = {\n",
    "#     'alpha': np.arange(0.1, 40, 0.4)\n",
    "    'alpha': np.arange(11, 20, 0.1)\n",
    "}\n",
    "\n",
    "lasso_grid_search = GridSearchCV(model, param_grid, cv=10)\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best R_squared from grid search: %.3f\"\n",
    "       % lasso_grid_search.score(X_train, y_train))\n",
    "print(lasso_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use alpha found to fit lasso\n",
    "# lasso = Lasso(alpha=14.1)\n",
    "lasso = Lasso(alpha=11.0)\n",
    "lasso.fit(X_train,y_train)\n",
    "y_lasso = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louis' solution from slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "paramgrid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "n = 5\n",
    "\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=paramgrid, cv=n, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train,y_train)\n",
    "\n",
    "best_r2 = grid_result.best_score_\n",
    "best_alpha = grid_result.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1) [   32.91131306 -2574.16607316  1239.05041471 ... -3710.78194219\n",
      "   -56.19594612 -1033.88942892] -6.157751680711613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilakelland/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "print(best_model, y_pred, r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Using the model from grid_search, predict the values in the test set and compare against your benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilakelland/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but Ridge was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "r2_test = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_baseline 0.557970448584349\n",
      "r2_lasso 0.5569192992970409\n",
      "r2_ridge 0.5582320311173267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_ridge = r2_score(y_test, y_rr)\n",
    "r2_lasso = r2_score(y_test, y_lasso)\n",
    "r2_baseline = r2_score(y_test, y_lr_baseline)\n",
    "\n",
    "\n",
    "print('r2_baseline', r2_baseline)\n",
    "print('r2_lasso', r2_lasso)\n",
    "print('r2_ridge', r2_ridge)\n",
    "\n",
    "# print('r2_test_ridge', r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE_ridge 1271132.6817950106\n",
      "MSE_lasso 1282119.3802162975\n",
      "MSE_baseline 1270203.416320679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# MSE = mean_squared_error(y_true,y_pred)  \n",
    "MSE_ridge = mean_squared_error(y, y_rr)\n",
    "MSE_lasso = mean_squared_error(y, y_lasso)\n",
    "MSE_baseline = mean_squared_error(y, y_lr_baseline)\n",
    "print('MSE_ridge', MSE_ridge)\n",
    "print('MSE_lasso', MSE_lasso)\n",
    "print('MSE_baseline', MSE_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
