{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay # want the ones with false neg not positives\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, plot_roc_curve, roc_curve, auc, RocCurveDisplay\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn import set_config # for plotting pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"data.csv\") \n",
    "\n",
    "# Separate out target, and drop id column\n",
    "X = df.drop(columns=['Loan_Status','Loan_ID'])\n",
    "y = df['Loan_Status'].replace({'Y':1, 'N':0})\n",
    "\n",
    "# Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=88)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into cat_feats and num_feats\n",
    "cat_feats = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "num_feats = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "\n",
    "def numFeat(data):\n",
    "    return data[num_feats]\n",
    "\n",
    "def catFeat(data):\n",
    "    return data[cat_feats]\n",
    "\n",
    "keep_num = FunctionTransformer(numFeat)\n",
    "keep_cat = FunctionTransformer(catFeat)\n",
    "\n",
    "# Note: Loan amount term is really more categorical, but leaving as numeric so can use in calculations - and will scale\n",
    "# Credit history will need to be converted to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns\n",
    "def replace_income_with_total_income_log(data):\n",
    "    data['Total_Income_Log'] = np.log(data['ApplicantIncome'] + data['CoapplicantIncome'])\n",
    "    data.drop(labels=['ApplicantIncome','CoapplicantIncome'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def add_LoanAmt_Term_Ratio_Log(data):\n",
    "    data['LoanAmt_Term_Ratio_Log']=  np.log(data.LoanAmount/data.Loan_Amount_Term)\n",
    "    return data\n",
    "\n",
    "def replace_loanamount_with_loanamount_log(X):\n",
    "    data['LoanAmount_Log'] = np.log(data.LoanAmount)\n",
    "    data.drop(labels=['LoanAmount'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def inject_features(data):\n",
    "    data['Total_Income_Log'] = 1 #np.log(data['ApplicantIncome'] + data['CoapplicantIncome'])\n",
    "    data['LoanAmt_Term_Ratio_Log']=  1 #np.log(data['LoanAmount']/data['Loan_Amount_Term'])\n",
    "    data['LoanAmount_Log'] = 1 #np.log(data['LoanAmount'])\n",
    "    data.drop(labels=['ApplicantIncome','CoapplicantIncome', 'LoanAmount'], axis=1, inplace=True)\n",
    "    data.reset_index(inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "add_total_income_log_object = FunctionTransformer(replace_income_with_total_income_log)\n",
    "add_loanamt_term_ratio_log_object = FunctionTransformer(add_LoanAmt_Term_Ratio_Log)\n",
    "add_loanamount_log_object = FunctionTransformer(replace_loanamount_with_loanamount_log)\n",
    "\n",
    "injected = FunctionTransformer(inject_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "class ToDenseTransformer():\n",
    "\n",
    "    # here you define the operation it should perform\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    # just return self\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "to_dense = ToDenseTransformer()\n",
    "\n",
    "\n",
    "selection = SelectKBest(k=3)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "base_model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null(data):\n",
    "    fill_NaN = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imputed = pd.DataFrame(fill_NaN.fit_transform(data))\n",
    "    imputed.columns = data.columns\n",
    "    imputed.index = data.index\n",
    "    return imputed\n",
    "\n",
    "fill_null = FunctionTransformer(fill_null)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_transform = Pipeline([('keep_num', keep_num),\n",
    "                            ('impute_median', fill_null),\n",
    "                            ('injected', injected),\n",
    "                            ('scaling', StandardScaler()),\n",
    "                            (\"kbest\", selection)]) \n",
    "\n",
    "\n",
    "categorical_transform = Pipeline([('keep_cat', keep_cat),\n",
    "                                ('impute_mode', SimpleImputer(strategy='most_frequent')), \n",
    "                                  ('one-hot-encode', OneHotEncoder(sparse=False)),\n",
    "                                  #(\"to_dense\", to_dense),\n",
    "                                 (\"pca\", pca)])\n",
    "\n",
    "all_features = FeatureUnion([('numeric_features', numeric_transform),\n",
    "                            ('categorical_features', categorical_transform)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6910569105691057\n",
      "Test set recall: 0.5487804878048781\n",
      "Precision: 0.6910569105691057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [2 3 4] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "main_pipeline = Pipeline([('all_features', all_features),\n",
    "                     (\"model\", LogisticRegression())])\n",
    "\n",
    "model = main_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# X_test = X_test.dropna()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision =  precision_score(y_test, y_pred, average='micro')\n",
    "\n",
    "print(f'Test set accuracy: {acc}')\n",
    "print(f'Test set recall: {recall}')\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
